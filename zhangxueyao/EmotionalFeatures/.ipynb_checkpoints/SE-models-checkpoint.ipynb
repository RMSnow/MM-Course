{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4663, 55), (4663, 110), (4663,))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con_se = np.load('./data/content_se_(4663, 55).npy')\n",
    "com_se = np.load('./data/pure_comments_100_se_(4663, 110).npy')\n",
    "label = np.load('./data/labels_(4663,).npy')\n",
    "\n",
    "con_se.shape, com_se.shape, label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ratio = 0.8\n",
    "\n",
    "rumor_sz = 2312\n",
    "truth_sz = 2351\n",
    "rumor_sz + truth_sz\n",
    "\n",
    "\n",
    "def split_dataset(arr):\n",
    "    assert len(arr) == rumor_sz + truth_sz\n",
    "\n",
    "    train_pos_sz = int(ratio * rumor_sz)\n",
    "    train_neg_sz = int(ratio * truth_sz)\n",
    "\n",
    "    train_pos_arr = arr[:train_pos_sz]\n",
    "    test_pos_arr = arr[train_pos_sz:rumor_sz]\n",
    "    train_neg_arr = arr[rumor_sz:(rumor_sz + train_neg_sz)]\n",
    "    test_neg_arr = arr[(rumor_sz + train_neg_sz):]\n",
    "\n",
    "    train_arr = np.concatenate([train_pos_arr, train_neg_arr], axis=0)\n",
    "    test_arr = np.concatenate([test_pos_arr, test_neg_arr], axis=0)\n",
    "\n",
    "    print(train_arr.shape, test_arr.shape)\n",
    "\n",
    "    return train_arr, test_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4663, 55), (4663, 110))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con_se.shape, com_se.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4663, 165)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "se = np.concatenate([con_se, com_se], axis=1)\n",
    "se.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(se, label, seed=0):    \n",
    "    X_train, X_test = split_dataset(se)\n",
    "    y_train, y_test = split_dataset(label)\n",
    "    \n",
    "    clf = RandomForestClassifier(random_state=seed)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "    test_label = y_test\n",
    "    \n",
    "    auc = roc_auc_score(test_label, y_pred)\n",
    "\n",
    "    y_pred[y_pred > 0.5] = 1\n",
    "    y_pred[y_pred <= 0.5] = 0\n",
    "\n",
    "    accuracy = accuracy_score(test_label, y_pred)\n",
    "    eval_dict = classification_report(test_label, y_pred, labels=[0, 1],\n",
    "                                      target_names=['truth', 'rumor'], output_dict=True)\n",
    "\n",
    "    print()\n",
    "    print('TEST_sz:', len(test_label))\n",
    "    print('test: {}+, {}-'.format(int(sum(test_label)), int(len(test_label) - sum(test_label))))\n",
    "    print()\n",
    "    print('Accuracy: {}'.format(accuracy))\n",
    "    print('AUC: {}'.format(auc))\n",
    "    print('Confusion Matrix:\\n {}'.format(confusion_matrix(test_label, y_pred)))\n",
    "    print()\n",
    "    print(classification_report(test_label, y_pred, labels=[0, 1],\n",
    "                                target_names=['truth', 'rumor'], digits=3))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3729, 55) (934, 55)\n",
      "(3729,) (934,)\n",
      "\n",
      "TEST_sz: 934\n",
      "test: 463+, 471-\n",
      "\n",
      "Accuracy: 0.6755888650963597\n",
      "AUC: 0.6748221925685436\n",
      "Confusion Matrix:\n",
      " [[360 111]\n",
      " [192 271]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       truth      0.652     0.764     0.704       471\n",
      "       rumor      0.709     0.585     0.641       463\n",
      "\n",
      "    accuracy                          0.676       934\n",
      "   macro avg      0.681     0.675     0.673       934\n",
      "weighted avg      0.681     0.676     0.673       934\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "train(con_se, label, seed=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3729, 110) (934, 110)\n",
      "(3729,) (934,)\n",
      "\n",
      "TEST_sz: 934\n",
      "test: 463+, 471-\n",
      "\n",
      "Accuracy: 0.7676659528907923\n",
      "AUC: 0.767713105244574\n",
      "Confusion Matrix:\n",
      " [[359 112]\n",
      " [105 358]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       truth      0.774     0.762     0.768       471\n",
      "       rumor      0.762     0.773     0.767       463\n",
      "\n",
      "    accuracy                          0.768       934\n",
      "   macro avg      0.768     0.768     0.768       934\n",
      "weighted avg      0.768     0.768     0.768       934\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "train(com_se, label, seed=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3729, 165) (934, 165)\n",
      "(3729,) (934,)\n",
      "\n",
      "TEST_sz: 934\n",
      "test: 463+, 471-\n",
      "\n",
      "Accuracy: 0.7762312633832976\n",
      "AUC: 0.776150646801759\n",
      "Confusion Matrix:\n",
      " [[370 101]\n",
      " [108 355]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       truth      0.774     0.786     0.780       471\n",
      "       rumor      0.779     0.767     0.773       463\n",
      "\n",
      "    accuracy                          0.776       934\n",
      "   macro avg      0.776     0.776     0.776       934\n",
      "weighted avg      0.776     0.776     0.776       934\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "train(se, label, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3729, 55) (934, 55)\n",
      "(3729,) (934,)\n",
      "\n",
      "TEST_sz: 934\n",
      "test: 463+, 471-\n",
      "\n",
      "Accuracy: 0.7387580299785867\n",
      "AUC: 0.7388305750826558\n",
      "Confusion Matrix:\n",
      " [[344 127]\n",
      " [117 346]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       truth      0.746     0.730     0.738       471\n",
      "       rumor      0.732     0.747     0.739       463\n",
      "\n",
      "    accuracy                          0.739       934\n",
      "   macro avg      0.739     0.739     0.739       934\n",
      "weighted avg      0.739     0.739     0.739       934\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "train(com_se[:, :55], label, seed=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3729, 55) (934, 55)\n",
      "(3729,) (934,)\n",
      "\n",
      "TEST_sz: 934\n",
      "test: 463+, 471-\n",
      "\n",
      "Accuracy: 0.7237687366167024\n",
      "AUC: 0.7237484695491877\n",
      "Confusion Matrix:\n",
      " [[342 129]\n",
      " [129 334]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       truth      0.726     0.726     0.726       471\n",
      "       rumor      0.721     0.721     0.721       463\n",
      "\n",
      "    accuracy                          0.724       934\n",
      "   macro avg      0.724     0.724     0.724       934\n",
      "weighted avg      0.724     0.724     0.724       934\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "train(com_se[:, 55:], label, seed=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(se, label, seed=0):    \n",
    "    X_train, X_test = split_dataset(se)\n",
    "    y_train, y_test = split_dataset(label)\n",
    "    \n",
    "    dt = DecisionTreeClassifier(random_state=seed)\n",
    "    dt.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = dt.predict(X_test)\n",
    "    test_label = y_test\n",
    "    \n",
    "    auc = roc_auc_score(test_label, y_pred)\n",
    "\n",
    "    y_pred[y_pred > 0.5] = 1\n",
    "    y_pred[y_pred <= 0.5] = 0\n",
    "\n",
    "    accuracy = accuracy_score(test_label, y_pred)\n",
    "    eval_dict = classification_report(test_label, y_pred, labels=[0, 1],\n",
    "                                      target_names=['truth', 'rumor'], output_dict=True)\n",
    "\n",
    "    print()\n",
    "    print('TEST_sz:', len(test_label))\n",
    "    print('test: {}+, {}-'.format(int(sum(test_label)), int(len(test_label) - sum(test_label))))\n",
    "    print()\n",
    "    print('Accuracy: {}'.format(accuracy))\n",
    "    print('AUC: {}'.format(auc))\n",
    "    print('Confusion Matrix:\\n {}'.format(confusion_matrix(test_label, y_pred)))\n",
    "    print()\n",
    "    print(classification_report(test_label, y_pred, labels=[0, 1],\n",
    "                                target_names=['truth', 'rumor'], digits=3))\n",
    "    print()\n",
    "    \n",
    "    return dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3729, 55) (934, 55)\n",
      "(3729,) (934,)\n",
      "\n",
      "TEST_sz: 934\n",
      "test: 463+, 471-\n",
      "\n",
      "Accuracy: 0.6156316916488223\n",
      "AUC: 0.6158327715948329\n",
      "Confusion Matrix:\n",
      " [[279 192]\n",
      " [167 296]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       truth      0.626     0.592     0.609       471\n",
      "       rumor      0.607     0.639     0.623       463\n",
      "\n",
      "    accuracy                          0.616       934\n",
      "   macro avg      0.616     0.616     0.616       934\n",
      "weighted avg      0.616     0.616     0.615       934\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "con_dt = train(con_se, label, seed=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3729, 110) (934, 110)\n",
      "(3729,) (934,)\n",
      "\n",
      "TEST_sz: 934\n",
      "test: 463+, 471-\n",
      "\n",
      "Accuracy: 0.721627408993576\n",
      "AUC: 0.7218270945967635\n",
      "Confusion Matrix:\n",
      " [[329 142]\n",
      " [118 345]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       truth      0.736     0.699     0.717       471\n",
      "       rumor      0.708     0.745     0.726       463\n",
      "\n",
      "    accuracy                          0.722       934\n",
      "   macro avg      0.722     0.722     0.722       934\n",
      "weighted avg      0.722     0.722     0.722       934\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "com_dt = train(com_se, label, seed=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3729, 165) (934, 165)\n",
      "(3729,) (934,)\n",
      "\n",
      "TEST_sz: 934\n",
      "test: 463+, 471-\n",
      "\n",
      "Accuracy: 0.7312633832976445\n",
      "AUC: 0.7314179196874442\n",
      "Confusion Matrix:\n",
      " [[336 135]\n",
      " [116 347]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       truth      0.743     0.713     0.728       471\n",
      "       rumor      0.720     0.749     0.734       463\n",
      "\n",
      "    accuracy                          0.731       934\n",
      "   macro avg      0.732     0.731     0.731       934\n",
      "weighted avg      0.732     0.731     0.731       934\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt = train(se, label, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([109,  86,  85,  84,  83,  82,  81,  80,  79,  78,  77,  76,  75,\n",
       "        74,  73,  72,  71,  70,  69,  68,  67,  66,  65,  64,  58,  59,\n",
       "        60,  61,  62,  30,  31,  28,   3,   4,   5,   6,   7,   8,   9,\n",
       "        10,  11,  12,  13,  29,  15,  14,  17,  27,  26,  25,  16,  23,\n",
       "        24,  21,  20,  19,  18,  22,  63,  49,  92,  91, 104,  90,  54,\n",
       "        56,  47, 101,  53, 103,  45,  42,  88,  35,  95,  94,  93, 100,\n",
       "        99, 108,  40,  57, 102,  97,  55,   0, 106,  46,  52,  48,  89,\n",
       "        98,  44,  51,  36,  32,  96, 107,   2,  37,  87,   1,  50,  43,\n",
       "        33,  34, 105,  38,  41,  39])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argsort(com_dt.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00944024,  0.01989879,  0.0171242 ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.0134755 ,  0.03236474,  0.04305343,\n",
       "        0.0065292 ,  0.01289358,  0.01765296,  0.06642155,  0.31316515,\n",
       "        0.00775281,  0.09453723,  0.00562387,  0.02093466,  0.01134487,\n",
       "        0.00555912,  0.00987533,  0.00409249,  0.01038419,  0.00080456,\n",
       "        0.02015801,  0.01237692,  0.00997814,  0.00494156,  0.0030341 ,\n",
       "        0.00941454,  0.00398543,  0.00799169,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.01812342,  0.00584872,  0.01070307,\n",
       "        0.00195045,  0.00146245,  0.00119999,  0.00714863,  0.00676314,\n",
       "        0.00663201,  0.01535425,  0.00931288,  0.01116617,  0.00738136,\n",
       "        0.00717334,  0.00416421,  0.00814307,  0.00500399,  0.00193373,\n",
       "        0.04308275,  0.00951271,  0.0155027 ,  0.00762811,  0.        ])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "com_dt.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
